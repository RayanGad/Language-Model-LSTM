{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jgjvWIqp0LcD"
      },
      "source": [
        "\n",
        "\n",
        "# Character-level language model\n",
        "\n",
        "In this notebook, we train a language model on a small corpus and use it to generate new text in the same style. We are defining the conditional probability of the next character in a sequence given characters up until the current time. To do this we will use an LSTM."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EtaK7Bun0LcG"
      },
      "outputs": [],
      "source": [
        "# Modules for Google drive\n",
        "from google.colab import drive\n",
        "from torchsummary import summary\n",
        "\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch import nn, optim\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cjt5HoLw1ROF",
        "outputId": "67059947-39b3-4148-e260-f2af4b750f75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# replace with your own root directory\n",
        "ROOT=\"/content/drive/MyDrive/Artificial Intelligence/Alice in wonderland/\"\n",
        "#data/alice_in_wonderland.txt"
      ],
      "metadata": {
        "id": "BF1-9mof2Tdi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4iTaaiTD0LcH"
      },
      "source": [
        "Convert characters from the text corpus into tokens from a fixed *vocabulary*.  Convert upper case letters to lower case. Characters other than letters, full-stop and space will be omitted (e.g. other punctuation, mumerical digits).  We will then use a one-hot encoding for each token as input to the RNN."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aQGSIkZ20LcI",
        "outputId": "abfffa89-f861-48a3-c00d-07eb72b7c7e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 8, 27, 11,  8, 10,  4, 27, 19, 14, 27,  3,  0, 13,  2,  4])\n",
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n"
          ]
        }
      ],
      "source": [
        "# character encoding: lower case letters, full-stop and space.\n",
        "chars = 'abcdefghijklmnopqrstuvwxyz. '\n",
        "input_size = len(chars)  # for one-hot encoding\n",
        "\n",
        "# define a mapping from char to integer (token index) and vice versa\n",
        "char_to_int = {}    # ensure the dictionaries are empty\n",
        "int_to_char = {}\n",
        "char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
        "int_to_char = dict((i, c) for i, c in enumerate(chars))\n",
        "\n",
        "def tokenize(data):\n",
        "    # tokenize text string\n",
        "    \n",
        "    # convert to lower case\n",
        "    data = data.lower()\n",
        "    \n",
        "    # integer encode (tokenize) each character; -1 if not in chars, drop these\n",
        "    idx = torch.tensor([char_to_int.get(char,-1) for char in data], dtype=torch.long)   # .get() returns value with specified key. Here key is character in dictionary.\n",
        "    idx = idx[idx != -1]  \n",
        "    \n",
        "    return idx\n",
        "\n",
        "def onehot(idx, input_size):\n",
        "    # convert to one-hot form (batch_size x sequence_length x input_size).\n",
        "    # works for any tensor size and adds one-hot encoding of indices as a new dimension at the end\n",
        "    inputs = torch.eye(input_size,dtype=int)[idx]    # .eye() retuens a 2-D tensor with ones on the diagonal and zeros elsewhere. input_size = number of rows.     \n",
        "    inputs = inputs.float()\n",
        "    return inputs\n",
        "ind=tokenize('i like to dance')\n",
        "print(ind)\n",
        "print(onehot(ind, input_size))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FkK_XA7O0LcL"
      },
      "source": [
        "To use the PyTorch data loader facilities, we need to define a new dataset to access the text corpus."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "onehot(3,28)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6_N5B_-GUeFU",
        "outputId": "e5842c34-922b-42af-b346-7d085ce10c11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D47XzMq70LcM"
      },
      "outputs": [],
      "source": [
        "class Alice(Dataset):\n",
        "    \"\"\" Alice in Wonderland custom dataset \"\"\"\n",
        "    \n",
        "    def __init__(self, size):\n",
        "        # read in the text and tokenize\n",
        "        f = open('/content/drive/MyDrive/Artificial Intelligence/Alice in wonderland/data/alice_in_wonderland.txt')\n",
        "        data = f.read()\n",
        "        self.idx = tokenize(data)  # store tokenized data (int)      \n",
        "        self.size = size    # the size of text windows to be used in training(here 50)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \"\"\" Returns one data item (token sequence of the given size) Returns a chunck of text\"\"\" \n",
        "        return self.idx[index:(index+self.size)]  # returns items in the self.size window ( here 50). when shuffle is true still covers all data items but in random order.\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.idx) - self.size  \n",
        "    \n",
        "dataset = Alice(50)\n",
        "train_dataloader = DataLoader(dataset, batch_size=64, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sS5zTL330LcN"
      },
      "source": [
        "Define the network. This is an LSTM followed by a fully connected layer. (Long short term memory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mUKutE3b0LcN"
      },
      "outputs": [],
      "source": [
        "class MyRNN(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        super(MyRNN, self).__init__()\n",
        "        \n",
        "        # single LSTM layer, with dropout(0.5)\n",
        "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=128, num_layers=1, batch_first=True) # (N,L,Hidden)\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "        self.linear = nn.Linear(128,input_size)\n",
        "        \n",
        "    def forward(self, input, zero_hidden = True):  #(64,50,128)\n",
        "        if zero_hidden:\n",
        "            # hidden state defaults to zero\n",
        "            output, hiddens = self.lstm(input)  # if dont give hidden, will initialize as zeros.   outputs are (64,50,128) \n",
        "        else:\n",
        "            # use the hidden state stored from previous invocation\n",
        "            output, hiddens = self.lstm(input, self.hiddens)    \n",
        "        \n",
        "        # update stored hidden state for future invocation\n",
        "        self.hiddens = hiddens\n",
        "        \n",
        "        output = self.dropout(output)\n",
        "        output = self.linear(output)\n",
        "        return output\n",
        "\n",
        "net = MyRNN(input_size)\n",
        "#net = nn.DataParallel(MyRNN)\n",
        "net = net.to(device)\n",
        "#summary(net.to(device), input_size=28)\n",
        "\n",
        "\n",
        "# net = MyRNN(input_size) \n",
        "\n",
        "# for param in net.parameters():\n",
        "#     print(param.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-_o-B5u0LcO"
      },
      "source": [
        "Train the network. Each window of text is trimmed by one token at the start for input and one token at the end for the target. This trains the network to predict the next character from all previous characters in the window.\n",
        "\n",
        "`nn.LSTM` will roll-out the LSTM to operate on the given sequence. We don't need to do this explicitly. Likewise, `nn.Linear` operates independently on each time step in the time dimension. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ADhGSz4k0LcP",
        "outputId": "efa7bacd-412e-4151-db5f-d215c00df4c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 1 loss:  1.956\n",
            "epoch: 2 loss:  1.495\n",
            "epoch: 3 loss:  1.354\n",
            "epoch: 4 loss:  1.283\n",
            "epoch: 5 loss:  1.242\n"
          ]
        }
      ],
      "source": [
        "nepochs = 5\n",
        "results_path = ROOT+'results/epochs50hidden128adam.pt'\n",
        "losses = np.zeros(nepochs)\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()  # LogSoftmax + negative logliklihood\n",
        "optimizer = optim.Adam(net.parameters())   # 0.002 by default\n",
        "\n",
        "net.train()    # to be sure we are in training mode\n",
        "for epoch in range(nepochs):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    n = 0\n",
        "    for i, idx in enumerate(train_dataloader, 0):\n",
        "        \n",
        "        inputs = onehot(idx, input_size)\n",
        "        \n",
        "        # trim to advance target by one timestep whilst keeping input and target sequences the same length\n",
        "        # idx = [a,b,c,d]\n",
        "        # index = [a,b,c]\n",
        "        # target = [b,c,d]\n",
        "        inputs = inputs[:,:-1,:] \n",
        "        inputs = inputs.to(device)\n",
        "        targets = idx[:,1:]\n",
        "        \n",
        "         # Zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward, backward, and update parameters\n",
        "        outputs = net(inputs)    # initial hidden state will default to zero\n",
        "        loss = loss_fn(outputs.transpose(1,2).cpu(), targets)    # compute loss over target outputs.\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    \n",
        "        # accumulate loss\n",
        "        running_loss += loss.item()\n",
        "        n += 1\n",
        "       \n",
        "    losses[epoch] = meanloss = running_loss / n\n",
        "    print(f\"epoch: {epoch+1} loss: {meanloss : .3f}\")\n",
        "    \n",
        "# save network parameters and losses\n",
        "torch.save({\"state_dict\": net.state_dict(), \"losses\": losses}, results_path)\n",
        "   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CiX4w5Bq0LcQ"
      },
      "source": [
        "Generate novel text primed by the given prior text.\n",
        "\n",
        "Run the model repeatedly on the currently generated text, starting with the given prior text.\n",
        "Select the maximum probability token as the next token in the sequence.\n",
        "\n",
        "In subsequent runs of the model, only input the most recently selected token since we use the final hidden state and cell state from the previous run to provide the history. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XWEPTWYt0LcR",
        "outputId": "561c1148-3b11-4720-af25-ba07c77c84bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 25, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "torch.Size([1, 1, 28])\n",
            "The queen turned to alice and she thought the was and said the mock turtle and the dormouse said the mock turtle and the dormouse said the mock turtle and the dormouse said the mock turtle and the dormouse said the mock turtle and the dormouse said the mock turtle and the dormouse said the mock turtle and the dormouse said the mock turtle and the dormouse said the mock turtle and the dormouse said the mock turtle and the \n"
          ]
        }
      ],
      "source": [
        "# restore model parameters and losses\n",
        "results_path = ROOT+'results/epochs50hidden128adam.pt'\n",
        "data = torch.load(results_path)\n",
        "net.load_state_dict(data[\"state_dict\"])\n",
        "\n",
        "# set prior text\n",
        "pretext = 'The queen turned to alice'\n",
        "idx = tokenize(pretext)    # initialise token sequence and generated sequence\n",
        "gen_length = 400    # length of generated text\n",
        "output = pretext    # initialise output text\n",
        "\n",
        "# sample from the network.\n",
        "zero_hidden = True    # initialise hidden state to zero for the first time through\n",
        "net.eval()    # set eval mode so that dropout is omitted by the module\n",
        "with torch.no_grad():    # turn off gradient calculations for the evaluation\n",
        "    for i in range(gen_length):\n",
        "        \n",
        "        inputs = onehot(idx, input_size)\n",
        "        inputs = torch.unsqueeze(inputs,0) # add batch dimension of size 1: 1 x len(idx) x input_size\n",
        "        inputs=inputs.to(device)\n",
        "        print(inputs.shape)\n",
        "        \n",
        "        outputs = net(inputs, zero_hidden)\n",
        "        _, predicted = torch.max(outputs, 2)   # what caharacter has the highest probability\n",
        "        \n",
        "        token = predicted[0,-1].item()    # extract final predicted token as input for next timestep\n",
        "        output = output + int_to_char[token]       # decode token and append to output\n",
        "        idx = torch.tensor([token])    # input sequence consisting of a single time step\n",
        "        zero_hidden = False               # pass on the hidden state in future iterations\n",
        "          \n",
        "print(output)   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40xclY9h0LcS"
      },
      "source": [
        "Plot the mean loss after each epoch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "g2AJ73y10LcS",
        "outputId": "7364cd38-f909-4e1b-c607-8d654be0abf7"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd5xU5d3+8c+FIEoTlcUuqAS7qFl7CZaoMZbkUaOxxRaDsaGG2BUT46PG3h71p0aNNYklxt5FjG0xdgXFSlBBVAQ78P39cZ+VYdldZmFnzszO9X695rWz55yd852zM3PNue9z7qOIwMzMalenvAswM7N8OQjMzGqcg8DMrMY5CMzMapyDwMysxjkIzMxqnIOgAki6R9Kv2nvZNtYwWNK49n7cSiApJA3I7l8q6cR2fvzjJF3Rno9ZapL2kTRyHv7+akmntmdNBY/9jqQti1x2np6HJZ3zLqBaSZpa8Gs34Btgevb7byLi+mIfKyJ+Uopla4mk5YCxwGURcVBLy0XEkPZed0ScNjd/J2kD4H6gd0RMz6b9P2C3ZqZNL0XttUTScGBAROzZEdbTnrxHMJciokfjDXgP2L5g2vchIMlhWx57A58Cu0rqmncxRWogvQfXLpi2CTCuybRNgRFlrKtVkubLuwZrXw6CdtbYxCLpaEkfAn+RtLCkOyVNlPRpdn/pgr95VNIB2f19JI2UdFa27NuSfjKXyy4naYSkKZIelHSxpOuKfB4rZ+v6TNIrknYomLetpFezx/2vpN9l0/tkz+0zSZ9IelxSs68xSRtKelbS5Oznhk2e4x8lPZGt435JfVqpVaQgOAH4Dti+lWVnadKQtKOk5yV9LmmspG2y6QtJulLSB9lzPLWlD0BJwxu3q6T+WVPUryS9J+ljScc393cR8R3wFOmDHkl9gfmBvzWZNhAYIamrpPMkjc9u5zWGXsHr7ihJE7K69y2ocVFJd2TP8xlghSbPYSVJD2T/t9GSftFkm/2fpLslfQFs1uRvi3l9t/j/lLSXpHclTWppW7XheZwv6f1s/ihJm2TTtwGOI31RmCrphWz6vpJey+p6S9JvCh6rxdezpCUl3ZI957clHdbaeiqdg6A0FgcWAfoBB5K281+y35cFvgIuauXv1wNGA32AM4Ersw+7ti57A/AMsCgwHNirmOIldQH+RWq26AscClwvacVskStJzV89gdWAh7PpR5G+zdYBi5HeELONYSJpEeAu4IKstnOAuyQtWrDY7sC+2frnB37XSskbA0sDN5E+RIvtb1kXuBYYBvQmffi+k82+GpgGDADWArYCDijmcQtqWhHYAjhJ0sotLDciWy/Zz5HZrXDa2xExDjgeWB9YExgErEsKv0aLAwsBSwH7AxdLWjibdzHwNbAEsF92A0BSd+AB0uulL6lp6hJJqxQ89u7An4CeWX2Finl9N/v/zNbxf6TX5pKk18PStKzF55F5lrR9Fsmez98lLRAR9wKnATdne+2DsuUnANsBvbL6zpXUuDfW7Os5C4N/AS+QtvUWwFBJW7eynsoWEb7N44304bFldn8w8C2wQCvLrwl8WvD7o8AB2f19gDcL5nUjfZgu3pZlSW/IaUC3gvnXAde1UNNgYFx2fxPgQ6BTwfwbgeHZ/feA3wC9mjzGH4B/ktpHW9teewHPNJn2JLBPwXM8oWDeb4F7W3m8K4Dbs/sbkPYK+hbMj8aaSB/wp2b3LwPObebxFiP1+SxYMO2XwCMtrH9443YF+mfrW7pg/jPAbq1s90mAgPOBXwM9gI8Kpv0lW3YssG3B324NvFPwOF8BnQvmTyAFx3zZNlmpYN5pwMjs/q7A403qugw4uWCbXdtk/vfbscjXd7P/T+Ak4KaCed1J758tm3ncVp9HC7V8Cgxq+n9qZfnbgcNbez2Tvny912TasQX/pzmup9Ju3iMojYkR8XXjL5K6Sbos2/39nPQtsHdLTQ2kD2EAIuLL7G6PNi67JPBJwTSA94usf0ng/YiYUTDtXdK3H4CdgG2BdyU9ptTpCfBn4E3g/mw3+5hWHv/dJtMKHx8KnhfwJS08f0kLArsA1wNExJOkoNq95af3vWVIH65N9QO6AB9kzQKfkT4Y+xbxmI2Kqp/UNNSDtGe1KekDeSrpf9U4rbF/oOl2ezeb1mhSRExrZr11pAND3m/yt436Aes1Ptfs+e5B+kLRqMXXTpGv75a2x5KFjx0RX5CCsTlzeh5I+l3W1DM5ex4LkfaWW6r9J5Keypp+PiO9rhuXb+n13A9Yssn2Oo70BaIqOQhKo2lzyFGkZoL1IqIXM3f7W2ruaQ8fAItI6lYwbZki/3Y8sIxmbd9fFvgvQEQ8GxE7kj4Ybyc1xxARUyLiqIhYHtgBOFLSFi08fr8m075//Db6OWm3/hJJHyr1yyxFcc1D79Okjblg+jdAn4jond16RcSqc1Ffq7IvDM+S+jWWiIjXs1mPZ9PWYGYQNN1uy2bT5mQiae+w8P+/bMH994HHCp5r70jNGoVHX7U2TPG8vL4/KKwre70u2sKyrT6PrD/g98AvgIUjojcwuaCOWZ6DUv/KLcBZwGLZ8nc3Lt/K6/l9UnNd4fbqGRHbNreeauAgKI+epN32z7L28ZNLvcKIeJd0VMpwSfNn39pb7ERt4mnSt7bfS+oiaXD2tzdlj7WHpIUidXZ+DswAkLSdpAFZH8Vk0uG0M5p5/LuBgZJ2l9RZ0q7AKsCdc/FUfwVcBaxOapJYE9gIGCRp9Tn87ZXAvpK2kNRJ0lKSVoqID0j9I2dL6pXNW0HSj+aivmKMAA4H/l0wbWQ27YOIaNxruRE4QVJd1tl6Eqm5r1WRDkO9lfRa6Ja1yxcG5Z2k/8de2f+7i6R1WunXaGpeXt//ALaTtLGk+UnNMc1+LhXxPHqSgmIi0FnSSaQvCY0+AvoXfMGZH+iaLT9N6UCLrRoXbuX1/AwwRemAkAUlzSdpNUnrtLCeilc1hVa584AFgY9JTQH3lmm9e5DazCcBpwI3k77ptioiviV98P+EVPMlwN4F31b3At7JmgGGZOsB+AHwIDCV1OZ/SUQ80szjTyJ10B2V1fZ7YLuI+LgtT05SY0fdeRHxYcFtFGkbt7pXEBHPkHUQkt7ojzHzG/fepA+KV0ntzP8gdVCWwmOkvavCTtiR2bTHC6adSgr3F4GXgOeyacU4hNQc8yGpff8vjTMiYgrpA3A30h7Gh8AZpA/JYsz16zsiXgEOJnXsfkDa1q2d2Nji8wDuy9Y9htRk9DWzNiP9Pfs5SdJz2fM+jLRH+ympOfGOguWbfT1ngbQd6UvH29nzvoLUDDXbeua4ESqAss4NqwGSbgZej4iS75GYWfXwHkEHlu3er5A1bWwD7Ehq0zcz+57Peu3YFie1qS5K2t0+KCL+k29JZlZp3DRkZlbj3DRkZlbjqq5pqE+fPtG/f/+8yzAzqyqjRo36OCLqmptXdUHQv39/Ghoa8i7DzKyqSGp6Nv/33DRkZlbjHARmZjXOQWBmVuMcBGZmNc5BYGZW4xwEZmY1zkFgZlbjaicI3nkHhg6F777LuxIzs4pSO0Hw4otw/vlw4YV5V2JmVlFqJwi23x623RaGD4cPPsi7GjOzilE7QSClPYJvvoFhw/KuxsysYtROEAAMGJBC4PrrYcSIOS9vZlYDaisIAI47DpZdFg45BKZNy7saM7Pc1V4QdOsG55wDL70El1ySdzVmZrmrvSAA+J//gR//GE48ET76KO9qzMxyVZtBIKXDSL/6Co45Ju9qzMxyVZtBALDiinDkkXD11fDkk3lXY2aWm9oNAoATToClloKDD4bp0/OuxswsF7UdBD16wNlnw3/+A5dfnnc1Zma5qO0gAPjFL2DzzeH44+Hjj/Ouxsys7BwEjR3HU6bAscfmXY2ZWdmVLAgkXSVpgqSXW5i/sKTbJL0o6RlJq5WqljlaZRU47DC48kp45pncyjAzy0Mp9wiuBrZpZf5xwPMRsQawN3B+CWuZs5NPhsUWSx3HM2bkWoqZWTmVLAgiYgTwSSuLrAI8nC37OtBf0mKlqmeOevWCs86Choa0Z2BmViPy7CN4AfgfAEnrAv2ApZtbUNKBkhokNUycOLF0Fe2+O2yySeor+KS1DDMz6zjyDILTgd6SngcOBf4DNHswf0RcHhH1EVFfV1dXuookuOgi+OyzdI6BmVkNyC0IIuLziNg3ItYk9RHUAW/lVc/31lgj9RNceik891ze1ZiZlVxuQSCpt6T5s18PAEZExOd51TOLU06Bujp3HJtZTSjl4aM3Ak8CK0oaJ2l/SUMkDckWWRl4WdJo4CfA4aWqpc1694YzzoCnnoJrrsm7GjOzklJE5F1Dm9TX10dDQ0PpVzRjBmy8Mbz5JowZk8LBzKxKSRoVEfXNzfOZxS3p1AkuvjgNO3HSSXlXY2ZWMg6C1qy1FgwZkgLhhRfyrsbMrCQcBHNy6qmw8MLpGsdV1oxmZlYMB8GcLLIInH46jBwJ11+fdzVmZu3OQVCM/faDddaBYcPg88o4wtXMrL04CIrR2HH80UcwfHje1ZiZtSsHQbHWWQcOOAAuuABeeSXvaszM2o2DoC1OOw0WWsgdx2bWoTgI2qJPH/jTn+DRR+Hmm/OuxsysXTgI2urXv4a114ajjkqXtzQzq3IOgraab740VPX48ekcAzOzKucgmBsbbAD77gvnnAOvv553NWZm88RBMLdOPx26d4dDD3XHsZlVNQfB3OrbF/74R3jwQbj11ryrMTObaw6CeXHQQemKZkccAV98kXc1ZmZzxUEwLzp3Tmccv/9+OsfAzKwKOQjm1cYbw557wllnwRtv5F2NmVmbOQjaw5lnQteucNhh7jg2s6pTymsWXyVpgqSXW5i/kKR/SXpB0iuS9i1VLSW3xBLpgvf33gt33JF3NWZmbVLKPYKrgW1amX8w8GpEDAIGA2dLmr+E9ZTWIYfAqqvC0KHw1Vd5V2NmVrSSBUFEjAA+aW0RoKckAT2yZaeVqp6S69IlnXH8zjtwxhl5V2NmVrQ8+wguAlYGxgMvAYdHxIzmFpR0oKQGSQ0TJ04sZ41tM3gw7LZbOtnsrbfyrsbMrCh5BsHWwPPAksCawEWSejW3YERcHhH1EVFfV1dXzhrb7qyz0mGlQ4fmXYmZWVHyDIJ9gVsjeRN4G1gpx3rax1JLwUknwb/+BXfdlXc1ZmZzlGcQvAdsASBpMWBFoGO0pwwdCiutBIcfDl9/nXc1ZmatKuXhozcCTwIrShonaX9JQyQNyRb5I7ChpJeAh4CjI+LjUtVTVvPPDxdeCGPHpqYiM7MKpqiyE6Dq6+ujoaEh7zKKs8suqXnotdegX7+8qzGzGiZpVETUNzfPZxaX0tlng5QGpTMzq1AOglJadlk4/ni47Ta47768qzEza5aDoNSOOgoGDEjjEH3zTd7VmJnNxkFQal27wgUXwJgxcO65eVdjZjYbB0E5/OQnsOOO6Ypm48blXY2Z2SwcBOVy3nkwY0ZqKjIzqyAOgnLp3x+OPRb+9jd46KG8qzEz+56DoJyGDYPlloNDD4Vvv827GjMzwEFQXgsuCOefn04wu/DCvKsxMwMcBOW3/fbw05/C8OEwfnze1ZiZOQhycd55qWlo2LC8KzEzcxDkYsAA+P3v4YYbYMSIvKsxsxrnIMjLscemgegOOQSmVe8VOs2s+jkI8tKtWzrT+KWX4OKL867GzGqYgyBPP/sZbLVVuqLZhx/mXY2Z1SgHQZ6kdBjpV1/BMcfkXY2Z1SgHQd4GDkzDTlxzDfz733lXY2Y1yEFQCU44AZZeGg4+GKZPz7saM6sxDoJK0L17uprZ88/DZZflXY2Z1ZhSXrz+KkkTJL3cwvxhkp7Pbi9Lmi5pkVLVU/F22QU23zxd0WzixLyrMbMaUso9gquBbVqaGRF/jog1I2JN4FjgsYj4pIT1VLbGjuOpU9M5BmZmZVKyIIiIEUCxH+y/BG4sVS1VY5VV4PDD4cor4emn867GzGpE7n0EkrqR9hxuaWWZAyU1SGqY2NGbTU4+GZZYwh3HZlY2uQcBsD3wRGvNQhFxeUTUR0R9XV1dGUvLQc+ecNZZMGpU2jMwMyuxSgiC3XCz0Kx++UvYdNPUVzBpUt7VmFkHl2sQSFoI+BHwzzzrqDgSXHQRTJ6cjiIyMyuhUh4+eiPwJLCipHGS9pc0RNKQgsV+DtwfEV+Uqo6qtfrqaWTSyy9PzURmZiWiiMi7hjapr6+PhoaGvMsoj8mT0xAUyy2Xhp/oVAkteWZWjSSNioj65ub5k6WSLbQQnHlmOpT06qvzrsbMOigHQaXbay/YcMM0Oumnn+ZdjZl1QA6CStepU7pwzaRJ6boFZmbtzEFQDdZcEw46CC65JA1MZ2bWjhwE1eKPf4RFFklHElVZB7+ZVTYHQbVYeGE4/XR44gm47rq8qzGzDsRBUE323RfWWw+GDUuHlpqZtQMHQTXp1CmdcTxhAgwfnnc1ZtZBOAiqTX09/PrX6doFLzd7zR8zszZxEFSj005LJ5u549jM2oGDoBotumgKg8ceg5tuyrsaM6tyDoJqdcABsPba8LvfwZQpeVdjZlXMQVCt5psvnXE8fnw6x8DMbC45CKrZ+uvDfvvBuefCa6/lXY2ZVSkHQbU7/XTo0QMOPdQdx2Y2VxwE1a6uLjUNPfQQ/OMfeVdjZlWoqCCQdLikXkqulPScpK1KXZwVacgQGDQIjjwSvvDF3sysbYrdI9gvIj4HtgIWBvYCTi9ZVdY2nTunjuNx4+BPf8q7GjOrMsUGgbKf2wJ/jYhXCqZZJdhoo3QRm7POgjFj8q7GzKpIsUEwStL9pCC4T1JPYEZrfyDpKkkTJLU4DoKkwZKel/SKpMeKL9uadeaZsOCCcNhh7jg2s6IVGwT7A8cA60TEl0AXYN85/M3VwDYtzZTUG7gE2CEiVgV2KbIWa8nii8Mpp8B998E//5l3NWZWJYoNgg2A0RHxmaQ9gROAVsdBjogRwCetLLI7cGtEvJctP6HIWqw1hxwCq60GQ4fCl1/mXY2ZVYFig+D/gC8lDQKOAsYC187jugcCC0t6VNIoSXu3tKCkAyU1SGqYOHHiPK62g+vcOQ1V/e676RwDM7M5KDYIpkVEADsCF0XExUDPeVx3Z+CHwE+BrYETJQ1sbsGIuDwi6iOivq6ubh5XWwN+9CP45S9Tn8HYsXlXY2YVrtggmCLpWNJho3dJ6kTqJ5gX44D7IuKLiPgYGAEMmsfHtEZnnQVduqQmIjOzVhQbBLsC35DOJ/gQWBr48zyu+5/AxpI6S+oGrAd4wJz2suSScNJJcOed6WZm1gJFkYcZSloMWCf79Zk5de5KuhEYDPQBPgJOJtuLiIhLs2WGkY4+mgFcERHnzamO+vr6aGhoKKrmmvftt+mM42+/hVdegQUWyLsiM8uJpFERUd/svGKCQNIvSHsAj5JOJNsEGBYRZR/cxkHQRg89BFtuCX/4A5x4Yt7VmFlOWguCYpuGjiedQ/CriNgbWBfwp0o12GIL2GWXdEWzd97Juxozq0DFBkGnJk1Bk9rwt5a3s8+GTp3giCPyrsTMKlCxH+b3SrpP0j6S9gHuAu4uXVnWrpZZBk44AW6/He69N+9qzKzCtKWzeCdgo+zXxyPitpJV1Qr3Ecylb76B1VdP9196Cbp2zbceMyur9ugjICJuiYgjs1suIWDzoGtXuPBCeOMNOOecvKsxswrSahBImiLp82ZuUyR9Xq4irZ1svTX87Gdw6qnw3nt5V2NmFaLVIIiInhHRq5lbz4joVa4irR2dey7MmAG/+13elZhZhfCRP7Wmf3847jj4+9/hwQfzrsbMKoCDoBYNGwbLLw+HHprOOjazmuYgqEULLADnnw+vvw4XXJB3NWaWMwdBrdpuu3Q75RQYPz7vaswsRw6CWnbeefDdd+44NqtxDoJatsIK8Pvfw403wqOP5l2NmeXEQVDrjjkG+vVLHcfffZd3NWaWAwdBrevWLTURvfwyXHxx3tWYWQ4cBAY77pjOOj75ZPjww7yrMbMycxAYSOkw0q++gqOPzrsaMyszB4ElAwemo4euvRaeeCLvasysjEoWBJKukjRB0sstzB8sabKk57PbSaWqxYp0/PGw9NJw8MEwbVre1ZhZmZRyj+BqYJs5LPN4RKyZ3f5QwlqsGN27pyGqX3gBLr0072rMrExKFgQRMQL4pFSPbyWy887pOscnnggTJsx5eTOrenn3EWwg6QVJ90hataWFJB0oqUFSw8SJE8tZX+2R0gVspk6FY4/NuxozK4M8g+A5oF9EDAIuBG5vacGIuDwi6iOivq6urmwF1qyVV04Xur/qKjjqKHD4mnVouQVBRHweEVOz+3cDXST1yasea+Lkk2GffdLJZsstlzqSP/0076rMrARyCwJJi0tSdn/drJZJedVjTXTvDn/5C7zyShql9LTTUiD84Q/wua9SataRlPLw0RuBJ4EVJY2TtL+kIZKGZIvsDLws6QXgAmC3iIhS1WNzaaWV4Kab0pFEm22W9hSWWw7OPBO++CLv6sysHajaPnvr6+ujoaEh7zJqV0MDnHQS3HMP9O2bLnv5m9+ki92YWcWSNCoi6publ/dRQ1Zt6uvh7rvT2cerrQZDh8KAAem8A1/20qwqOQhs7my4ITz0ULr16wcHHQQrrpj6FXxWsllVcRDYvNl8cxg5MjUVLboo7LcfrLIK3HADTJ+ed3VmVgQHgc07CbbZBp59Fm6/PfUX7LEHDBoEt94KVdYPZVZrHATWfqR0bYPnn09HGk2bBjvtBD/8Idx1lwPBrEI5CKz9deoEu+6arnp2zTUweXI6F2GDDeDBBx0IZhXGQWCl07kz7L03vP46XH45jB8PP/5xOh/h8cfzrs7MMg4CK70uXeDXv4Y33kgD2o0eDZtumi6P+cwzeVdnVvMcBFY+XbvCIYfA2LHw5z/Dc8/BeuvBDjukfgUzy4WDwMqvW7d0Wcy33oJTT03NRGutBb/4Bbz6at7VmdUcB4Hlp2fPNKrp22+nC+Hcc086W3mvveDNN/OuzqxmOAgsf717p1FN334bhg2DW25Jg90dcAC8+27e1Zl1eA4Cqxx9+sAZZ6Qmo4MPhr/+FX7wg3R//Pi8qzPrsBwEVnkWXxzOPz81D+23Xzr0dIUV4MgjfR1lsxJwEFjlWmaZNKrp6NGw224pHJZfPg19/ckneVdn1mE4CKzyLb98GtX01VfToaann54ujnPKKemsZTObJw4Cqx4rrphGNX3xRdhySxg+PAXC6af7amlm88BBYNVntdXSkUUNDWn8omOPTXsN554LX32Vd3VmVcdBYNWrcVTTf/8bVl89dSYPGACXXOKrpZm1QSkvXn+VpAmSXp7DcutImiZp51LVYh1c46imjzyS9gwOPhgGDoSrrvLV0syKUMo9gquBbVpbQNJ8wBnA/SWsw2rF4MEwYgTcey/07Qv77w8rrwzXX++rpZm1omRBEBEjgDkd43cocAvgg8OtfUhpVNOnn4Z//hO6d4c994Q11kj9CjNm5F2hWcXJrY9A0lLAz4H/K2LZAyU1SGqYOHFi6Yuz6ielQ02few7+9rcUADvvnPoV7rzTF8cxK5BnZ/F5wNERMcevaBFxeUTUR0R9XV1dGUqzDqNTJ9hll3S1tL/+FaZMge23T/0KDzzgQDAj3yCoB26S9A6wM3CJpJ/lWI91ZPPNl5qIXnsNrrgCPvgAttpqZr+CWQ3LLQgiYrmI6B8R/YF/AL+NiNvzqsdqRJcuqRN5zBi46KJ01bQf/SiFwtNP512dWS5KefjojcCTwIqSxknaX9IQSUNKtU6zonXtmg4zHTsWzj47XSFt/fVTs9F//pN3dWZlpaiyNtL6+vpoaGjIuwzraKZOTddT/vOf4dNPYaed0lhGq66ad2Vm7ULSqIiob26ezyw2A+jRIw1V8fbbcPLJcP/96WzlPfZIzUdmHZiDwKzQQgulwezefhuOPhpuvz2dlLb//vDOO3lXZ1YSDgKz5iy6KPzv/6arpR16aDo7eeBA+O1v4b//zbs6s3blIDBrzWKLpVFNx45N11C+4op0tbQjjoCPPsq7OrN24SAwK8ZSS6VRTceMSf0GF16YBrg75hiYNCnv6szmiYPArC3694crr0wnpv3853DmmeniOMOH+2ppVrUcBGZz4wc/gOuug5deSoPcnXJKCom99kqX1Xz33bwrNCuag8BsXqy6Kvz972lwu223hfvug/32S6Gw/PKpX+GGG9KQFmYVyieUmbWnCHjlFXj44XShnEcfhc8+S/NWWgk23zzdBg9ORyaZlUlrJ5Q5CMxKafr0NHxFYzCMGAFffJHmDRo0Mxg23RR69cq3VuvQHARmleK77+DZZ2cGwxNPwDffpNFR6+ths81SMGy0EXTrlne11oE4CMwq1ddfw5NPzgyGp59O11nu0iVdM6ExGNZbLw2UZzaXHARm1WLqVBg5MgXDww+nTugIWHBB2HjjmcHwwx9C5855V2tVxEFgVq0+/TT1KzTuMbz0Upres2e6jkJjMKyxRroam1kLHARmHcWECelIpMZgGDMmTV9kkZmhsNlm6QglKddSrbI4CMw6qnHjUiA0NiW9916avvjiM49I2myzdPazg6GmOQjMakFEGj67MRQeeQQ+/DDN69dvZihsvnkaO8lqioPArBZFwOuvzwyGRx+FTz5J8wYOnPXktrq6PCu1MnAQmBnMmAEvvjgzGEaMgClT0rzVV5/15LbevfOt1dpdLkEg6SpgO2BCRKzWzPwdgT8CM4BpwNCIGDmnx3UQmLWTadNg1KiZwTByZDqvoVMnWHvtmcGw8cbQvXve1do8yisINgWmAte2EAQ9gC8iIiStAfwtIlaa0+M6CMxK5Jtv0gltjcHw1FPpTOjOndMJbY3BsP76sMACeVdrbZRb05Ck/sCdzQVBk+U2AK6KiJXn9JgOArMy+eIL+Pe/ZwZDQ0NqXlpgAdhww5nBUF+fzoS2itZaEOR6aqKknwP/C/QFftrKcgcCBwIsu+yy5SnOrNZ17w4//nG6QbrwzuOPzwyGE05I03v0gE02mRkMgwalsZOsalTKHsGmwEkRseWcHogpDvwAAAjVSURBVNN7BGYV4uOP4bHHZgbD66+n6QsvnM56bgyGVVbxOQwVoGL3CBpFxAhJy0vqExEf512PmRWhTx/Yaad0Axg/fuZZzw8/DLffnqb37Tvz/IXNN4cVVnAwVJjcgkDSAGBs1lm8NtAV8FXAzarVkkvC7runG8A778x61vPNN6fpyyyTgmGzzWCttdJlPz3kdq5KedTQjcBgoA/wEXAy0AUgIi6VdDSwN/Ad8BUwzIePmnVQEfDGG7Oe9fxxwc7/Msukk9xWXDHdGu8vu6z7G9qJTygzs8oyYwa89hq8+iqMHp1uY8akn5Mnz1yua1cYMGBmMBSGhS/12SYV30dgZjWmUydYddV0KxQBEyfOGgyjR6fQuPPOdF5Do0UWmTUcGn8OGODzHNrIQWBmlUNKnct9+6ZDUgtNm5b6HQpDYswYeOABuOaaWR+jX7/mQ2LppX3dhmY4CMysOnTunL7tDxgAP21y2tGUKakPomlIPPFEuupbowUXTJ3TzfVH1PD4Sg4CM6t+PXum8ZHWXnvW6RHwwQezhsPo0fDCC3DbbTB9+sxl6+qa34tYYQWYf/7yPp8yc2exmdWmb7+Ft96aPSTGjIGPPpq5XKdO6cI+zYXEkktWzTkR7iw2M2tq/vnTJT1Xamasy88+m9nUVBgSjzwCX301c7nu3WcPh4ED061Xr/I9l3nkIDAza6p3b1hnnXQrNGMG/Pe/s+9FPP10OmGusIVl8cVnP+R14MC0d1Fhg/Q5CMzMitWpUzr5bZllYIstZp339dcwduzsIXHrrTCpYNCEzp1h+eWbb2pabLFcmpocBGZm7WGBBZo/NwJSEIwZM3tI3H9/ug5Eo169Wm5qKuHFgdxZbGaWl+nT4f33Z++sHj0a3ntv1mWXWgqOOAKOOmquVuXOYjOzSjTffNC/f7ptvfWs8778Et58c9ZwWGKJkpThIDAzq0TdusEaa6RbiflcazOzGucgMDOrcQ4CM7Ma5yAwM6txDgIzsxrnIDAzq3EOAjOzGucgMDOrcVU3xISkicC7c/nnfYCP27Gc9lKpdUHl1ua62sZ1tU1HrKtfRNQ1N6PqgmBeSGpoaayNPFVqXVC5tbmutnFdbVNrdblpyMysxjkIzMxqXK0FweV5F9CCSq0LKrc219U2rqttaqqumuojMDOz2dXaHoGZmTXhIDAzq3EdMggkbSNptKQ3JR3TzPyukm7O5j8tqX+F1LWPpImSns9uB5SprqskTZD0cgvzJemCrO4XJa1dIXUNljS5YHudVIaalpH0iKRXJb0i6fBmlin79iqyrrJvr2y9C0h6RtILWW2nNLNM2d+TRdaV13tyPkn/kXRnM/Paf1tFRIe6AfMBY4HlgfmBF4BVmizzW+DS7P5uwM0VUtc+wEU5bLNNgbWBl1uYvy1wDyBgfeDpCqlrMHBnmbfVEsDa2f2ewJhm/o9l315F1lX27ZWtV0CP7H4X4Glg/SbL5PGeLKauvN6TRwI3NPf/KsW26oh7BOsCb0bEWxHxLXATsGOTZXYErsnu/wPYQpIqoK5cRMQI4JNWFtkRuDaSp4Dekkpz8dS21VV2EfFBRDyX3Z8CvAYs1WSxsm+vIuvKRbYdpma/dsluTY9SKft7ssi6yk7S0sBPgStaWKTdt1VHDIKlgPcLfh/H7G+I75eJiGnAZGDRCqgLYKesOeEfkpYpcU3FKrb2PGyQ7drfI2nVcq442yVfi/RNslCu26uVuiCn7ZU1dTwPTAAeiIgWt1kZ35PF1AXlf0+eB/wemNHC/HbfVh0xCKrZv4D+EbEG8AAzU9+a9xxp/JRBwIXA7eVasaQewC3A0Ij4vFzrnZM51JXb9oqI6RGxJrA0sK6k1cq17tYUUVdZ35OStgMmRMSoUq6nqY4YBP8FClN76Wxas8tI6gwsBEzKu66ImBQR32S/XgH8sMQ1FauYbVp2EfF54659RNwNdJHUp9TrldSF9GF7fUTc2swiuWyvOdWV1/ZqUsNnwCPANk1m5fGenGNdObwnNwJ2kPQOqfl4c0nXNVmm3bdVRwyCZ4EfSFpO0vykzpQ7mixzB/Cr7P7OwMOR9bzkWVeTduQdSO28leAOYO/saJj1gckR8UHeRUlavLFtVNK6pNdzST88svVdCbwWEee0sFjZt1cxdeWxvbJ11Unqnd1fEPgx8HqTxcr+niymrnK/JyPi2IhYOiL6kz4jHo6IPZss1u7bqvO8/HEliohpkg4B7iMdqXNVRLwi6Q9AQ0TcQXrD/FXSm6TOyN0qpK7DJO0ATMvq2qfUdQFIupF0REkfSeOAk0kdZ0TEpcDdpCNh3gS+BPatkLp2Bg6SNA34CtitDIG+EbAX8FLWtgxwHLBsQV15bK9i6spje0E6oukaSfORwudvEXFn3u/JIuvK5T3ZVKm3lYeYMDOrcR2xacjMzNrAQWBmVuMcBGZmNc5BYGZW4xwEZmY1zkFgVkZKI4DONqKkWZ4cBGZmNc5BYNYMSXtmY9U/L+mybHCyqZLOzcauf0hSXbbsmpKeygYmu03Swtn0AZIezAZ5e07SCtnD98gGMHtd0vVlGPnWrFUOArMmJK0M7ApslA1INh3YA+hOOrtzVeAx0pnOANcCR2cDk71UMP164OJskLcNgcZhJtYChgKrkK5PsVHJn5RZKzrcEBNm7WAL0uBiz2Zf1hckDVM8A7g5W+Y64FZJCwG9I+KxbPo1wN8l9QSWiojbACLia4Ds8Z6JiHHZ788D/YGRpX9aZs1zEJjNTsA1EXHsLBOlE5ssN7fjs3xTcH86fh9aztw0ZDa7h4CdJfUFkLSIpH6k98vO2TK7AyMjYjLwqaRNsul7AY9lVwkbJ+ln2WN0ldStrM/CrEj+JmLWRES8KukE4H5JnYDvgIOBL0gXLzmB1FS0a/YnvwIuzT7o32LmaKN7AZdlI0d+B+xSxqdhVjSPPmpWJElTI6JH3nWYtTc3DZmZ1TjvEZiZ1TjvEZiZ1TgHgZlZjXMQmJnVOAeBmVmNcxCYmdW4/w8Tqu6PcGcL9gAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# restore model parameters and losses\n",
        "results_path = ROOT+'results/epochs50hidden128adam.pt'\n",
        "data = torch.load(results_path)\n",
        "losses = data[\"losses\"]\n",
        "\n",
        "plt.plot(losses, 'r')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.title('Training loss on Alice in Wonderland dataset' )\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QaUMskpw0LcT"
      },
      "source": [
        "## Optional exercises\n",
        "1. Retrain the model using a vanilla RNN and see what happens to the quality of the language model.\n",
        "2. Add a second LSTM layer and train on a larger body of text. Does this improve the quality of the generated text?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TamGiQir0LcT"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}